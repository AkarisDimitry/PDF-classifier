{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyON7/DATXrmPk3Tcf3eaoMU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkarisDimitry/PDF-classifier/blob/main/PDF_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Clustering de Documentos de Texto\n",
        "\n",
        "Este proyecto proporciona un script en Python para realizar clustering no supervisado en datos de texto a partir de archivos PDF y DOC. El script lee y preprocesa los datos de texto, los convierte en una matriz TF-IDF y luego realiza cuatro tipos diferentes de clustering: K-means, jerárquico, Latent Dirichlet Allocation (LDA) y DBSCAN."
      ],
      "metadata": {
        "id": "_RvPakyXfXBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjxnoXGyfAxa",
        "outputId": "317058f7-52db-4cce-88db-796e0866349f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "0h6XqiA8fQ4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "x5JsHWdwfRea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando las librerías necesarias\n",
        "Aquí importamos todas las librerías necesarias para nuestro código. Esto incluye librerías para manipulación de archivos, procesamiento de lenguaje natural, extracción de características, modelado de tópicos y algoritmos de clustering.\n",
        "\n"
      ],
      "metadata": {
        "id": "wmR_ARWlgPIc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "9wEsaAbNeCcO",
        "outputId": "3fff653b-4d13-44d5-e492-7a711e256a90"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b9bd9491f107>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPyPDF2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPdfFileReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdocx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PyPDF2'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Importing required libraries\n",
        "import os\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "from PyPDF2 import PdfFileReader\n",
        "from docx import Document\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from gensim import corpora, models\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "\n",
        "# Downloading necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesamiento de datos\n",
        "En esta sección, definimos las funciones para el preprocesamiento de nuestros datos de texto y la conversión en una matriz TF-IDF."
      ],
      "metadata": {
        "id": "XY4yujz2gTu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ Data Preprocessing ------------------\n",
        "\n",
        "def preprocess_text(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Preprocesses the given text by removing English stopwords and tokenizing.\n",
        "    \"\"\"\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    word_tokens = word_tokenize(text)\n",
        "    filtered_text = [word for word in word_tokens if word.casefold() not in stop_words]\n",
        "    return \" \".join(filtered_text)\n",
        "\n",
        "def get_tfidf_matrix(texts: list) -> np.array:\n",
        "    \"\"\"\n",
        "    Converts a list of text documents into a TF-IDF matrix.\n",
        "    \"\"\"\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
        "    return tfidf_matrix\n"
      ],
      "metadata": {
        "id": "RccGuZ4VeZRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Leyendo los archivos\n",
        "Aquí definimos las funciones para leer archivos PDF y DOC y extraer su contenido de texto.\n",
        "\n"
      ],
      "metadata": {
        "id": "jM-rmA6QgWFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ File Reading ------------------\n",
        "\n",
        "def read_pdf_file(file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Reads the text content from a PDF file.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'rb') as file:\n",
        "        pdf = PdfFileReader(file)\n",
        "        text = \" \".join(page.extractText() for page in pdf.pages)\n",
        "    return text\n",
        "\n",
        "def read_doc_file(file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Reads the text content from a DOC file.\n",
        "    \"\"\"\n",
        "    doc = Document(file_path)\n",
        "    text = \" \".join(paragraph.text for paragraph in doc.paragraphs)\n",
        "    return text\n",
        "\n",
        "def get_text_from_files(directory: str) -> tuple:\n",
        "    \"\"\"\n",
        "    Extracts text from all PDF and DOC files in the given directory and its subdirectories.\n",
        "    Returns a tuple of two lists: the first list contains the file names,\n",
        "    and the second list contains the corresponding text content.\n",
        "    \"\"\"\n",
        "    text = []\n",
        "    names = []\n",
        "    for dirpath, dirs, files in os.walk(directory):\n",
        "        for filename in files:\n",
        "            if filename.endswith('.pdf'):\n",
        "                text += [read_pdf_file(os.path.join(dirpath, filename))]\n",
        "                names += [dirpath+filename]\n",
        "            elif filename.endswith('.doc') or filename.endswith('.docx'):\n",
        "                text += [read_doc_file(os.path.join(dirpath, filename))]\n",
        "                names += [dirpath+filename]\n",
        "    return names, text\n"
      ],
      "metadata": {
        "id": "dA955ysaebqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Clustering**\n",
        "Definimos las funciones para realizar el clustering de nuestros documentos usando varios algoritmos.\n",
        "## K-means\n",
        "El algoritmo K-means particiona el conjunto de datos en K grupos distintos y no superpuestos donde cada punto de datos pertenece al grupo con la media más cercana. El algoritmo comienza inicializando K centroides de grupos. Cada punto de datos se asigna entonces al centroide más cercano, y cada centroide se actualiza para ser la media de los puntos de datos asignados a él. Este proceso se repite hasta que las asignaciones ya no cambian o se alcanza un número máximo de iteraciones."
      ],
      "metadata": {
        "id": "U6aLfhqNfniB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def kmeans_clustering(tfidf_matrix: np.array, num_clusters: int) -> list:\n",
        "    \"\"\"\n",
        "    Performs K-means clustering on the given TF-IDF matrix.\n",
        "    \"\"\"\n",
        "    km = KMeans(n_clusters=num_clusters)\n",
        "    km.fit(tfidf_matrix)\n",
        "    clusters = km.labels_.tolist()\n",
        "    return clusters"
      ],
      "metadata": {
        "id": "8Su-S9YNfzhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering Jerárquico\n",
        "El clustering jerárquico crea un árbol de grupos. El algoritmo comienza tratando cada punto de datos como un solo grupo y luego fusiona los dos grupos que son más similares hasta que solo queda un grupo (o K grupos). El resultado es una representación basada en árboles de los datos (un dendrograma) que muestra el orden en el que se fusionaron los grupos."
      ],
      "metadata": {
        "id": "55XuF_mtf1fK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hierarchical_clustering(tfidf_matrix: np.array, num_clusters: int) -> list:\n",
        "    \"\"\"\n",
        "    Performs hierarchical clustering on the given TF-IDF matrix.\n",
        "    \"\"\"\n",
        "    hc = AgglomerativeClustering(n_clusters=num_clusters, affinity='euclidean', linkage='ward')\n",
        "    clusters = hc.fit_predict(tfidf_matrix.toarray())\n",
        "    return clusters"
      ],
      "metadata": {
        "id": "lHLSNymof7wO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Latent Dirichlet Allocation (LDA)\n",
        "LDA es un tipo de modelo de tópicos probabilístico que supone que cada documento es una mezcla de un cierto número de tópicos y cada palabra en el documento es atribuible a uno de los tópicos del documento. El algoritmo usa un proceso generativo y aplica el teorema de Bayes para inferir la mezcla de tópicos y las asignaciones de tópicos que más probablemente generaron los documentos observados.\n",
        "\n"
      ],
      "metadata": {
        "id": "qhQPLlEif8SL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lda_clustering(preprocessed_documents: list, num_topics: int) -> list:\n",
        "    \"\"\"\n",
        "    Performs LDA (Latent Dirichlet Allocation) to identify topics in the given preprocessed documents.\n",
        "    \"\"\"\n",
        "    texts = [document.split() for document in preprocessed_documents]\n",
        "    dictionary = corpora.Dictionary(texts)\n",
        "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "    lda = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)\n",
        "    topics = lda.print_topics(num_words=4)\n",
        "    return topics"
      ],
      "metadata": {
        "id": "uxKheQmFgBr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DBSCAN\n",
        "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) es un algoritmo de clustering basado en la densidad. El algoritmo comienza explorando el conjunto de datos desde un punto aleatorio, y si hay al menos 'min_samples' puntos a una distancia de 'eps' de ese punto, se crea un nuevo grupo. Luego, el algoritmo agrega iterativamente los puntos cercanos a una distancia de 'eps' al grupo. Si un punto no está a una distancia de 'eps' de ningún otro punto, se considera ruido.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ucp0ezVygDyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dbscan_clustering(tfidf_matrix: np.array, eps: float, min_samples: int) -> list:\n",
        "    \"\"\"\n",
        "    Performs DBSCAN clustering on the given TF-IDF matrix.\n",
        "    \"\"\"\n",
        "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "    clusters = dbscan.fit_predict(tfidf_matrix.toarray())\n",
        "    return clusters"
      ],
      "metadata": {
        "id": "a3P3vtm_gGrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualización**\n",
        "Finalmente, definimos las funciones para visualizar nuestros resultados de clustering."
      ],
      "metadata": {
        "id": "bbZsp8GUgdYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ Visualization ------------------\n",
        "\n",
        "def plot_clusters(tfidf_matrix: np.array, clusters: list) -> None:\n",
        "    \"\"\"\n",
        "    Plots a 2D scatter plot of the given TF-IDF matrix, colored by cluster assignment.\n",
        "    \"\"\"\n",
        "    pca = PCA(n_components=2)\n",
        "    reduced_features = pca.fit_transform(tfidf_matrix.toarray())\n",
        "    plt.scatter(reduced_features[:,0], reduced_features[:,1], c=clusters)\n",
        "    plt.show()\n",
        "\n",
        "def plot_dendrogram(model, **kwargs):\n",
        "    \"\"\"\n",
        "    Plots a dendrogram for the given AgglomerativeClustering model.\n",
        "    \"\"\"\n",
        "    children = model.children_\n",
        "    distance = np.arange(children.shape[0])\n",
        "    no_of_observations = np.arange(2, children.shape[0]+2)\n",
        "    linkage_matrix = np.column_stack([children, distance, no_of_observations]).astype(float)\n",
        "    dendrogram(linkage_matrix, **kwargs)\n"
      ],
      "metadata": {
        "id": "AahlGz_uegwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Script Principal**\n",
        "Leemos y preprocesamos los documentos, realizamos el clustering y visualizamos los resultados.\n",
        "\n"
      ],
      "metadata": {
        "id": "SVahAKgoggj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ Main Script ------------------\n",
        "\n",
        "# Read and preprocess documents\n",
        "names, your_documents = get_text_from_files('/home/akaris/Documents/bibliografia/VDW')\n",
        "preprocessed_documents = [preprocess_text(doc) for doc in your_documents]\n",
        "tfidf_matrix = get_tfidf_matrix(preprocessed_documents)\n",
        "\n",
        "# Perform clustering\n",
        "kmeans_clusters = kmeans_clustering(tfidf_matrix, num_clusters=3)\n",
        "hierarchical_clusters = hierarchical_clustering(tfidf_matrix, num_clusters=3)\n",
        "lda_topics = lda_clustering(preprocessed_documents, num_topics=3)\n",
        "dbscan_clusters = dbscan_clustering(tfidf_matrix, eps=0.5, min_samples=5)\n",
        "\n",
        "# Print clustering results\n",
        "print(names)\n",
        "print(kmeans_clusters)\n",
        "print(hierarchical_clusters)\n",
        "print(lda_topics)\n",
        "print(dbscan_clusters)\n",
        "\n",
        "# Plot K-means clusters\n",
        "plot_clusters(tfidf_matrix, kmeans_clusters)\n",
        "\n",
        "# Plot hierarchical clusters\n",
        "hc = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
        "hc = hc.fit(tfidf_matrix.toarray())\n",
        "plt.title('Hierarchical Clustering Dendrogram')\n",
        "plot_dendrogram(hc, labels=hc.labels_)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kRaH9_hCehfx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}